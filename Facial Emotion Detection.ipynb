{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "922c1b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing.image import load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D,Dropout,Flatten,MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d4ab0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Dir = 'images/train'\n",
    "Test_Dir = 'images/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46350377",
   "metadata": {},
   "source": [
    "### Function is used to collect file paths and associated labels from a directory structure where each subdirectory corresponds to a different class, and images within each subdirectory belong to that class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59e7a209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createdataframe(dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for label in os.listdir(dir):\n",
    "        for imagename in os.listdir(os.path.join(dir, label)):\n",
    "            image_paths.append(os.path.join(dir, label, imagename))\n",
    "            labels.append(label)\n",
    "        print(label, \"completed\")\n",
    "    return image_paths, labels\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43e25098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n",
      "                              image     label\n",
      "0          images/train\\angry\\0.jpg     angry\n",
      "1          images/train\\angry\\1.jpg     angry\n",
      "2         images/train\\angry\\10.jpg     angry\n",
      "3       images/train\\angry\\1015.jpg     angry\n",
      "4       images/train\\angry\\1016.jpg     angry\n",
      "...                             ...       ...\n",
      "2231  images/train\\surprise\\894.jpg  surprise\n",
      "2232  images/train\\surprise\\909.jpg  surprise\n",
      "2233  images/train\\surprise\\960.jpg  surprise\n",
      "2234  images/train\\surprise\\964.jpg  surprise\n",
      "2235  images/train\\surprise\\972.jpg  surprise\n",
      "\n",
      "[2236 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame()\n",
    "train['image'],train['label'] = createdataframe(Train_Dir)\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3c37837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n",
      "                             image     label\n",
      "0       images/test\\angry\\1024.jpg     angry\n",
      "1       images/test\\angry\\1071.jpg     angry\n",
      "2       images/test\\angry\\1106.jpg     angry\n",
      "3       images/test\\angry\\1124.jpg     angry\n",
      "4       images/test\\angry\\1127.jpg     angry\n",
      "..                             ...       ...\n",
      "983  images/test\\surprise\\9806.jpg  surprise\n",
      "984  images/test\\surprise\\9830.jpg  surprise\n",
      "985  images/test\\surprise\\9853.jpg  surprise\n",
      "986  images/test\\surprise\\9878.jpg  surprise\n",
      "987   images/test\\surprise\\993.jpg  surprise\n",
      "\n",
      "[988 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "test = pd.DataFrame()\n",
    "test['image'],test['label'] = createdataframe(Test_Dir)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58487a27",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2f9f02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The tqdm library is used to create progress bars, \n",
    "allowing you to visualize the progress.\n",
    "\n",
    "\"\"\"\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "766d678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images):\n",
    "    features = []\n",
    "    for image in tqdm(images):\n",
    "        img = load_img(image, grayscale=True)\n",
    "        img = np.array(img)\n",
    "        features.append(img)\n",
    "    features = np.array(features)\n",
    "    features = features.reshape(len(features), 48, 48, 1)\n",
    "    return features\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ca58d1",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64c7bfe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d12dc5d4007490cb5a0bc3811d69c53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2236 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Star\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "467b524852064b0685980f776b871c6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/988 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The function processes a list of image file paths, loads and converts them to grayscale,\n",
    "and organizes them into a NumPy array suitable for further processing.\n",
    "\n",
    "\"\"\"\n",
    "train_features = extract_features(train['image'])\n",
    "test_features = extract_features(test['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b6a6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89598e1c",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "#### Normalize the pixel values of the image features. This normalization is a common preprocessing step in machine learning, especially when working with neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4dcf7306",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_features / 255.0\n",
    "x_test = test_features / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d293e478",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(train['label'])\n",
    "y_train = le.transform(train['label'])\n",
    "y_test = le.transform(test['label'])\n",
    "y_train = to_categorical(y_train, num_classes=7)\n",
    "y_test = to_categorical(y_test, num_classes=7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f01e4a",
   "metadata": {},
   "source": [
    "## Building the Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61025813",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# convolutional layers\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# flattening\n",
    "model.add(Flatten())\n",
    "\n",
    "# fully connected layers\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "# model compilation\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = 'accuracy' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ed61e3",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b1bc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=x_train, y =y_train, batch_size=128, epochs=100, validation_data=(x_train,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c8de80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3efab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4326f1f5",
   "metadata": {},
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cc8d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72e6755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f14b766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a00fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4583eed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2556a7ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33750788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c3df84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ced2e29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e5bbf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1855d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
